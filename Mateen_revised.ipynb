{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPsEhL2eabZDTOMVAA+v/4p",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Micro-Maxis/Intrusion-detection-system-dli/blob/main/Mateen_revised.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-KxlyabD2Zmw",
        "outputId": "9d0321bf-9ec9-4532-e499-9919aab197ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/ICL-ml4csec/Mateen.git\n",
        "!cd /content/Mateen\n",
        "!find . -name \"*.py\" -type f | head -10"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ntCU_3Fdft2",
        "outputId": "ac63ba4b-477a-46bc-d14c-2f643bb206c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'Mateen' already exists and is not an empty directory.\n",
            "./Mateen/Mateen.py\n",
            "./Mateen/MateenUtils/main.py\n",
            "./Mateen/MateenUtils/nsl_preprocessing.py\n",
            "./Mateen/MateenUtils/AE.py\n",
            "./Mateen/MateenUtils/merge_utils.py\n",
            "./Mateen/MateenUtils/utils.py\n",
            "./Mateen/MateenUtils/selection_utils.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Quick fix for Mateen - run this in Colab\n",
        "\n",
        "%cd /content/Mateen/MateenUtils\n",
        "\n",
        "# Read the current main.py\n",
        "with open('main.py', 'r') as f:\n",
        "    content = f.read()\n",
        "\n",
        "# Find and replace the ensemble_training function call in adaptive_ensemble\n",
        "# The issue is that load_mode parameter is not being passed\n",
        "\n",
        "# Replace the problematic line\n",
        "old_line = 'model = ensemble_training(x_train, y_train=y_train, num_epochs=100, mode=\"init\", scenario=args.dataset_name)'\n",
        "new_line = 'model = ensemble_training(x_train, y_train=y_train, num_epochs=100, mode=\"init\", scenario=args.dataset_name, load_mode=\"new\")'\n",
        "\n",
        "if old_line in content:\n",
        "    content = content.replace(old_line, new_line)\n",
        "    print(\"✓ Fixed ensemble_training call to force new model\")\n",
        "else:\n",
        "    print(\"⚠ Line not found, trying alternative fix...\")\n",
        "    # Alternative: modify the load_model function itself\n",
        "    old_load_func = '''def load_model(load_mode, input_shape, scenario, train_loader, data, num_epochs):\n",
        "    if load_mode == \"new\":\n",
        "        model = model_base.autoencoder(input_shape)\n",
        "        model = model_update(data, num_epochs=num_epochs, model=model)\n",
        "    else:\n",
        "        model = torch.load(f'Models/{scenario}.pth').to(device)\n",
        "    return model'''\n",
        "\n",
        "    new_load_func = '''def load_model(load_mode, input_shape, scenario, train_loader, data, num_epochs):\n",
        "    # Always create new model for now (override load_mode)\n",
        "    if load_mode == \"new\" or load_mode is None or True:  # Force new model creation\n",
        "        model = model_base.autoencoder(input_shape)\n",
        "        model = model_update(data, num_epochs=num_epochs, model=model)\n",
        "    else:\n",
        "        # Fallback to loading existing model (won't reach here due to condition above)\n",
        "        try:\n",
        "            model = torch.load(f'Models/{scenario}.pth').to(device)\n",
        "        except FileNotFoundError:\n",
        "            print(f\"Model file not found, creating new model instead...\")\n",
        "            model = model_base.autoencoder(input_shape)\n",
        "            model = model_update(data, num_epochs=num_epochs, model=model)\n",
        "    return model'''\n",
        "\n",
        "    # Replace the load_model function\n",
        "    if 'def load_model(' in content:\n",
        "        # Find the function and replace it\n",
        "        lines = content.split('\\n')\n",
        "        new_lines = []\n",
        "        in_load_model = False\n",
        "        skip_lines = False\n",
        "\n",
        "        for line in lines:\n",
        "            if 'def load_model(' in line:\n",
        "                in_load_model = True\n",
        "                skip_lines = True\n",
        "                new_lines.extend(new_load_func.split('\\n'))\n",
        "            elif in_load_model and (line.startswith('def ') or line.startswith('class ')):\n",
        "                in_load_model = False\n",
        "                skip_lines = False\n",
        "                new_lines.append(line)\n",
        "            elif not skip_lines:\n",
        "                new_lines.append(line)\n",
        "            elif in_load_model and line.strip() == 'return model':\n",
        "                skip_lines = False  # End of function\n",
        "\n",
        "        content = '\\n'.join(new_lines)\n",
        "        print(\"✓ Modified load_model function to always create new models\")\n",
        "\n",
        "# Write the fixed main.py\n",
        "with open('main.py', 'w') as f:\n",
        "    f.write(content)\n",
        "\n",
        "print(\"✅ main.py has been fixed to force new model creation!\")\n",
        "\n",
        "# Also ensure the Models directory exists\n",
        "import os\n",
        "os.makedirs('/content/Mateen/Models', exist_ok=True)\n",
        "print(\"✅ Models directory created\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KazH9S_c2dwG",
        "outputId": "54a6e65b-0ddf-45ba-b8ae-22a664be7a9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Mateen/MateenUtils\n",
            "✓ Fixed ensemble_training call to force new model\n",
            "✅ main.py has been fixed to force new model creation!\n",
            "✅ Models directory created\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/Mateen\n",
        "\n",
        "# Restart the imports to pick up the fixed main.py\n",
        "import sys\n",
        "sys.path.append('MateenUtils/')\n",
        "\n",
        "# Clear the module cache to reload the fixed main.py\n",
        "if 'main' in sys.modules:\n",
        "    del sys.modules['main']\n",
        "if 'Mateen_main' in sys.modules:\n",
        "    del sys.modules['Mateen_main']\n",
        "\n",
        "# Import the fixed modules\n",
        "import nsl_preprocessing as dp\n",
        "import utils\n",
        "import main as Mateen_main\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "class Args:\n",
        "    dataset_name = \"NSLKDD\"\n",
        "    window_size = 50000\n",
        "    performance_thres = 0.99\n",
        "    max_ensemble_length = 3\n",
        "    selection_budget = 0.01\n",
        "    mini_batch_size = 1000\n",
        "    retention_rate = 0.3\n",
        "    lambda_0 = 0.1\n",
        "    shift_threshold = 0.05\n",
        "    n_features = 15\n",
        "\n",
        "args = Args()\n",
        "\n",
        "print(\"=== Running Mateen with Enhanced NSL-KDD (Fixed Version) ===\")\n",
        "\n",
        "try:\n",
        "    # Load enhanced preprocessed data\n",
        "    print(\"1. Loading enhanced preprocessed NSL-KDD data...\")\n",
        "    x_train, x_test, y_train, y_test = dp.prepare_data(\"NSLKDD\")\n",
        "    print(f\"✓ Data loaded: Train {x_train.shape}, Test {x_test.shape}\")\n",
        "\n",
        "    # Partition data into windows\n",
        "    print(\"2. Partitioning data into windows...\")\n",
        "    x_slice, y_slice = dp.partition_array(x_data=x_test, y_data=y_test, slice_size=args.window_size)\n",
        "    print(f\"✓ Data partitioned into {len(x_slice)} windows\")\n",
        "\n",
        "    # Run Mateen adaptive ensemble\n",
        "    print(\"3. Running Mateen adaptive ensemble...\")\n",
        "    print(\"   (This will train a new autoencoder model from scratch)\")\n",
        "    predictions, probs_list = Mateen_main.adaptive_ensemble(x_train, y_train, x_slice, y_slice, args)\n",
        "    print(\"✓ Ensemble training completed!\")\n",
        "\n",
        "    # Evaluate results\n",
        "    print(\"4. Evaluating results...\")\n",
        "    result = utils.getResult(y_test, predictions)\n",
        "    auc_rocs = utils.auc_roc_in_chunks(y_test, probs_list, chunk_size=args.window_size)\n",
        "\n",
        "    # Display final results\n",
        "    print(f'\\n🎯 FINAL RESULTS WITH ENHANCED PREPROCESSING:')\n",
        "    print(f'   Average AUC-ROC: {np.mean(auc_rocs):.4f}')\n",
        "    print(f'   Standard Deviation: {np.std(auc_rocs):.4f}')\n",
        "    print(f'   Total Predictions: {len(predictions)}')\n",
        "    print(f'   Test Samples: {len(y_test)}')\n",
        "\n",
        "    # Save results\n",
        "    print(\"5. Saving results...\")\n",
        "    import os\n",
        "    os.makedirs('Results', exist_ok=True)\n",
        "\n",
        "    df = pd.DataFrame({\n",
        "        'Probabilities': probs_list,\n",
        "        'Predictions': predictions,\n",
        "        'True_Labels': y_test[:len(predictions)]  # Match lengths\n",
        "    })\n",
        "\n",
        "    result_file = f'Results/NSLKDD-enhanced-{args.n_features}feat-{args.selection_budget}.csv'\n",
        "    df.to_csv(result_file, index=False)\n",
        "\n",
        "    print(f'💾 Results saved to: {result_file}')\n",
        "\n",
        "    # Summary of improvements\n",
        "    print(f'\\n🚀 ENHANCED PREPROCESSING SUMMARY:')\n",
        "    print(f'   ✅ Consensus feature selection: {args.n_features} features from 54 engineered')\n",
        "    print(f'   ✅ AutoEncoder optimized: Normal samples only for training')\n",
        "    print(f'   ✅ Robust outlier handling and scaling')\n",
        "    print(f'   ✅ Advanced feature engineering (ratios, logs, security scores)')\n",
        "    print(f'   ✅ Mateen ensemble successfully trained and evaluated')\n",
        "\n",
        "    print(f'\\n🎉 SUCCESS! Enhanced NSL-KDD preprocessing integrated with Mateen!')\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"\\n❌ Error during execution: {e}\")\n",
        "    import traceback\n",
        "    traceback.print_exc()\n",
        "\n",
        "    # Show what worked\n",
        "    print(f\"\\n📊 What worked so far:\")\n",
        "    print(f\"   ✅ Enhanced preprocessing (15 features selected)\")\n",
        "    print(f\"   ✅ Data loading and partitioning\")\n",
        "    print(f\"   ❌ Mateen ensemble training (error occurred)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pivn2nuC2nsi",
        "outputId": "424d158e-e4bc-4e38-b50d-bdd05234a79c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Mateen\n",
            "=== Running Mateen with Enhanced NSL-KDD (Fixed Version) ===\n",
            "1. Loading enhanced preprocessed NSL-KDD data...\n",
            "=== Universal NSL-KDD Preprocessing ===\n",
            "1. Loading and cleaning data...\n",
            "   Original: Train (125973, 39), Test (22544, 39)\n",
            "2. Engineering features...\n",
            "   After engineering: (125973, 54)\n",
            "3. Handling outliers...\n",
            "4. Encoding categorical features...\n",
            "5. Scaling features...\n",
            "6. Selecting top 15 features...\n",
            "Selected 15 features using consensus:\n",
            "   1. root_shell\n",
            "   2. duration\n",
            "   3. num_root\n",
            "   4. num_file_creations\n",
            "   5. num_shells\n",
            "   6. num_access_files\n",
            "   7. is_guest_login\n",
            "   8. count\n",
            "   9. srv_count\n",
            "  10. serror_rate\n",
            "  11. srv_serror_rate\n",
            "  12. rerror_rate\n",
            "  13. srv_rerror_rate\n",
            "  14. same_srv_rate\n",
            "  15. diff_srv_rate\n",
            "   Final: Train (125973, 15), Test (22544, 15)\n",
            "   Class balance: Normal 67343, Attack 58630\n",
            "Enhanced NSLKDD for Mateen: Train (67343, 15), Test (22544, 15)\n",
            "✓ Data loaded: Train (67343, 15), Test (22544, 15)\n",
            "2. Partitioning data into windows...\n",
            "Data partitioned into 1 slices of size ~50000\n",
            "✓ Data partitioned into 1 windows\n",
            "3. Running Mateen adaptive ensemble...\n",
            "   (This will train a new autoencoder model from scratch)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [04:39<00:00,  2.79s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Updating Models Process Started!\n",
            "Step 1/1\n",
            "✓ Ensemble training completed!\n",
            "4. Evaluating results...\n",
            "Predicted Labels Counter({np.int64(0): 15245, np.int64(1): 7299})\n",
            "True Labels Counter({np.int64(1): 12833, np.int64(0): 9711})\n",
            "Positive label: 0\n",
            "General Accuracy: 72.6224\n",
            "Recall: 96.7151\n",
            "Precision: 61.6071\n",
            "F1 Score: 75.2685\n",
            "True Negative Rate: 54.3910\n",
            "True Positive Rate: 96.72%\n",
            "Macro Recall: 75.5530\n",
            "Macro Precision: 78.6183\n",
            "Macro F1 Score: 72.3054\n",
            "Balanced Accuracy: 75.5530\n",
            "\n",
            "🎯 FINAL RESULTS WITH ENHANCED PREPROCESSING:\n",
            "   Average AUC-ROC: 0.7344\n",
            "   Standard Deviation: 0.0000\n",
            "   Total Predictions: 22544\n",
            "   Test Samples: 22544\n",
            "5. Saving results...\n",
            "💾 Results saved to: Results/NSLKDD-enhanced-15feat-0.01.csv\n",
            "\n",
            "🚀 ENHANCED PREPROCESSING SUMMARY:\n",
            "   ✅ Consensus feature selection: 15 features from 54 engineered\n",
            "   ✅ AutoEncoder optimized: Normal samples only for training\n",
            "   ✅ Robust outlier handling and scaling\n",
            "   ✅ Advanced feature engineering (ratios, logs, security scores)\n",
            "   ✅ Mateen ensemble successfully trained and evaluated\n",
            "\n",
            "🎉 SUCCESS! Enhanced NSL-KDD preprocessing integrated with Mateen!\n"
          ]
        }
      ]
    }
  ]
}